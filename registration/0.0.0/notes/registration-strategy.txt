# General notes

We are using a SmoothingImagePyramid thus there is not downsampling.
As a consequence the NumberOfSpatialSamples does not have to be adapted to the settings for computing the SmoothingImagePyramid. In fact, I thus changed the name of the corresponding setting in the UI to GaussianSmoothingSigma

It is important to use a good mask in order to restrict the computation to relevant image regions.

In the belly region there are not many nuclei, thus we only rely on the muscles. Thus it could make sense to give them more weight during registration.

I do not have a good feeling for which NumberOfSpatialSamples makes sense. Maybe makes more sense to think in terms of fraction of pixels within mask? 
In our mask there are around 40.000.000 pixels.

Maybe less NumberOfSpatialSamples but rather high NumberOfIterations is a good strategy in order to explore more possibilities?

The neuropil is not present in one side of the belly region, thus putting to much weight on it during the registration might lead to bad alignments in this region. However, maybe, once the overall shape is well matched one can increase the weight during fine adjustments done at more fine grained BSplines.
 
Changing the smoothing ( = ImagePyramidSchedule ) during the registration can be confusing, because the quality metric values will change as well. However, the feeling is that in order to get high accuracy at fine grained BSplines one might need to smooth less?!

Also changing the channel weights will change the overall metric value, the ones of the individual channels stay the same though.

# Rotation pre-align

We use the rotation prealign as an inital transformation for the following ones.

# Similarity Experiment

All 3 channels were used, with muscles higher weight.

## Settings

(NumberOfSpatialSamples 10000)
(ImagePyramidSchedule 15 15 15) // smoothing sigma
(Metric0Weight 1.0 )
(Metric1Weight 3.0 )
(Metric2Weight 1.0 )

### Convergence

Interestingly after some stagnation between 999 and 1999 it really got much better at 2999, and then at the very end it again improved a lot.

0	-0.176163	-0.086445	-0.017606	-0.036900
999	-0.215712	-0.104530	-0.022902	-0.042477
1999	-0.228947	-0.116048	-0.022588	-0.045135
2999	-0.451720	-0.253755	-0.037443	-0.085637 (! strong improvement )
3999	-0.484159	-0.270394	-0.039010	-0.096735
4998	-0.489826	-0.284614	-0.036759	-0.094934
5999	-0.508868	-0.287047	-0.040110	-0.101491
6999	-0.491788	-0.272042	-0.036517	-0.110193
7999	-0.603236	-0.321716	-0.051854	-0.125957
8999	-0.991052	-0.432808	-0.126678	-0.178210 (! strong improvement )
9990	-0.987789	-0.411863	-0.131246	-0.182189
... I also ran again longer but after 10000 iterations there were no more improvements. 
This makes sense because visually the result at 10000 looked super good for only a similarity transform, i.e. I could not see how to improve this.



## Conclusions

The results in the end looked really very good! 

It seems to sometimes need that many (over even more) iterations to find a good registration.

It also seems that a strong smoothing is a good strategy (at least for finding an initial transformation), because, I think, it increases the basin of attraction, i.e. gradients are easier to find, especially given our binary input data.



# Affine

Maybe this can be skipped as there is no scientific reason why one sample should be shrunk in one specific direction more than in an other orthogonal direction ?!
I skipped it.


# BSpline 100

(Transform "BSplineTransform")
(MaximumNumberOfIterations 10000)
(ImagePyramidSchedule 15 15 15)
(NumberOfSpatialSamples 10000)
(FinalGridSpacingInVoxels 100 100 100 )
(Metric0Weight 1.0 )
(Metric1Weight 3.0 )
(Metric2Weight 1.0 )


## Convergence

0	-0.970031	-0.385899	-0.131624	-0.189259
999	-1.743090	-0.786659	-0.237570	-0.243720 (!)
1999	-1.731396	-0.798075	-0.234096	-0.231031
2999	-1.753035	-0.796310	-0.239703	-0.237615
3999	-1.764563	-0.810492	-0.236706	-0.243955
...
9999	-1.758065	-0.814303	-0.234547	-0.240120

Looked super good.


# BSpline 40


(Transform "BSplineTransform")
(MaximumNumberOfIterations 1000)
(ImagePyramidSchedule 15 15 15)
(NumberOfSpatialSamples 10000)
(FinalGridSpacingInVoxels 40 40 40 )
(Registration "MultiMetricMultiResolutionRegistration" )
(Metric0Weight 1.0 )
(Metric1Weight 3.0 )
(Metric2Weight 3.0 ) (! increased => sum weight increases)


## Convergence


0	-2.260248	-0.802621	-0.233172	-0.252703
999	-2.826055	-0.881758	-0.315233	-0.332866

Visual inspection looked good.


# BSpline 10

(Transform "BSplineTransform")
(MaximumNumberOfIterations 20000)
(ImagePyramidSchedule 2 2 2)
(NumberOfSpatialSamples 10000)
(FinalGridSpacingInVoxels 10 10 10 )
(Registration "MultiMetricMultiResolutionRegistration" )
(Metric0Weight 1.0 )
(Metric1Weight 3.0 )
(Metric2Weight 3.0 )

## Convergence

0	-0.990674	-0.320771	-0.116196	-0.107105
999	-1.408272	-0.382236	-0.183522	-0.158490
1999	-1.503421	-0.378669	-0.201400	-0.173518
2999	-1.590716	-0.397182	-0.222692	-0.175153
3999	-1.526799	-0.377565	-0.214996	-0.168082
4999	-1.608387	-0.374712	-0.227718	-0.183507
5999	-1.633175	-0.389392	-0.232624	-0.181970
6999	-1.625030	-0.387114	-0.238305	-0.174333
7999	-1.642454	-0.379603	-0.244494	-0.176457
19999	-1.709767	-0.395723	-0.258848	-0.179167

Looks visually ok...but somehow I feel we need better information for better matching...




